{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pyspark\n",
    "import findspark as fs\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Spark session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanBody(df):\n",
    "    for j in range(df.shape[0]):\n",
    "        soup=bs(df._Body.iloc[j])\n",
    "        s=\"\"\n",
    "        for i in range(len(soup.findAll(lambda tag: tag.name == 'p'))):\n",
    "            s+=(soup.find_all('p')[i].get_text())+' '\n",
    "        s=s[:-1] \n",
    "        df.loc[df.index[j], 'new_body'] = s\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"seed.csv\")\n",
    "df = cleanBody(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_Id', '_PostTypeId', '_CreationDate', '_Score', '_ViewCount', '_Body',\n",
       "       '_OwnerUserId', '_LastActivityDate', '_Title', '_Tags', '_AnswerCount',\n",
       "       '_CommentCount', '_FavoriteCount', '_LastEditorUserId',\n",
       "       '_AcceptedAnswerId', '_LastEditDate', '_ParentId', '_Category',\n",
       "       'new_body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(df[['new_body','_Category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting to training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[new_body: string, _Category: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training, validation = spark_df.randomSplit([0.7, 0.3], seed=7)\n",
    "training.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|            new_body|  _Category|label|               words|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|+1, it's a good idea|        avp|  7.0|[+1,, it's, a, go...|   [+1,, good, idea]|(500,[168,391,458...|(500,[168,391,458...|[10.0051587301587...|[0.10005158730158...|       7.0|\n",
      "|As discussed in t...|arabic.meta|  6.0|[as, discussed, i...|[discussed, propo...|(500,[0,4,5,6,12,...|(500,[0,4,5,6,12,...|[27.3333333333333...|[0.27333333333333...|       0.0|\n",
      "|As far as the que...|  agur.meta|  4.0|[as, far, as, the...|[far, question, r...|(500,[41,94,109,1...|(500,[41,94,109,1...|[16.8861111111111...|[0.16886111111111...|       7.0|\n",
      "|For both of the m...|arabic.meta|  6.0|[for, both, of, t...|[main, potential,...|(500,[12,15,19,26...|(500,[12,15,19,26...|[28.5,9.0,22.3333...|[0.285,0.09,0.223...|       0.0|\n",
      "|For example, this...|       beer|  9.0|[for, example,, t...|[example,, questi...|(500,[44,57,59,81...|(500,[44,57,59,81...|[20.9523809523809...|[0.20952380952380...|       0.0|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Validation set accuracy = 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer , IDF , StringIndexer ,StopWordsRemover\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Configure an ML pipeline\n",
    "indexer = StringIndexer(inputCol=\"_Category\", outputCol=\"label\")\n",
    "tokenizer = Tokenizer(inputCol=\"new_body\", outputCol=\"words\")\n",
    "stopwordsRemover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=stopwordsRemover.getOutputCol(), outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100,  maxDepth=20)\n",
    "pipeline = Pipeline(stages=[indexer, tokenizer,stopwordsRemover, hashingTF,idf, rf])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 500]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=4) \n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModelRF = crossval.fit(training)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "predictions = cvModelRF.transform(validation)\n",
    "predictions.show(5)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Validation set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"label\", outputCol=\"predictedLabel\")\n",
    "opdata = labelConverter.transform(predictions)\n",
    "op =(opdata.select('predictedLabel').toPandas())\n",
    "op.rename(columns={'predictedLabel':'rf_prediction'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a mapping between the labels and the categories using the StringIndexer and stores it in a dictionary dct\n",
    "\n",
    "category = predictions.select('_Category')\n",
    "labels = predictions.select('label')\n",
    "number = labels.toPandas()\n",
    "cat = category.toPandas()\n",
    "dct = {}\n",
    "df3 =pd.concat([number,cat], axis=1)\n",
    "for index, r in df3.iterrows():\n",
    "    key = r['label'] \n",
    "    val = r['_Category'] \n",
    "    if key not in dct:\n",
    "        dct[key] = val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7.0: 'avp',\n",
       " 6.0: 'arabic.meta',\n",
       " 4.0: 'agur.meta',\n",
       " 9.0: 'beer',\n",
       " 2.0: 'bricks',\n",
       " 8.0: 'arabic',\n",
       " 1.0: 'ai',\n",
       " 5.0: 'agur',\n",
       " 3.0: 'bioinformatics',\n",
       " 0.0: '3dprinting'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save model : \n",
    "\n",
    "# cvModelRF.save(\"classification_model\")\n",
    "\n",
    "# can be loaded easily later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on the test data. \n",
    "\n",
    "test = pd.read_csv(\"input_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Id</th>\n",
       "      <th>_PostTypeId</th>\n",
       "      <th>_CreationDate</th>\n",
       "      <th>_Score</th>\n",
       "      <th>_ViewCount</th>\n",
       "      <th>_Body</th>\n",
       "      <th>_OwnerUserId</th>\n",
       "      <th>_LastActivityDate</th>\n",
       "      <th>_Title</th>\n",
       "      <th>_Tags</th>\n",
       "      <th>_AnswerCount</th>\n",
       "      <th>_CommentCount</th>\n",
       "      <th>_FavoriteCount</th>\n",
       "      <th>_LastEditorUserId</th>\n",
       "      <th>_AcceptedAnswerId</th>\n",
       "      <th>_LastEditDate</th>\n",
       "      <th>_ParentId</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-25T19:48:36.693</td>\n",
       "      <td>6</td>\n",
       "      <td>157.0</td>\n",
       "      <td>&lt;p&gt;Are questions related to &lt;a href=\"http://ww...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2011-10-26T05:35:32.733</td>\n",
       "      <td>Are questions about non-LEGO brick toys on-topic?</td>\n",
       "      <td>&lt;discussion&gt;&lt;on-topic&gt;</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-26T05:35:32.733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-25T19:55:17.860</td>\n",
       "      <td>3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>&lt;p&gt;What is a good tag for purchasing/acquiring...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2011-10-26T05:32:58.667</td>\n",
       "      <td>Nomenclature of [Purchasing] tag</td>\n",
       "      <td>&lt;discussion&gt;&lt;tagging&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2011-10-26T05:32:58.667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _Id  _PostTypeId            _CreationDate  _Score  _ViewCount  \\\n",
       "0    1            1  2011-10-25T19:48:36.693       6       157.0   \n",
       "1    2            1  2011-10-25T19:55:17.860       3        53.0   \n",
       "\n",
       "                                               _Body  _OwnerUserId  \\\n",
       "0  <p>Are questions related to <a href=\"http://ww...           6.0   \n",
       "1  <p>What is a good tag for purchasing/acquiring...          13.0   \n",
       "\n",
       "         _LastActivityDate                                             _Title  \\\n",
       "0  2011-10-26T05:35:32.733  Are questions about non-LEGO brick toys on-topic?   \n",
       "1  2011-10-26T05:32:58.667                   Nomenclature of [Purchasing] tag   \n",
       "\n",
       "                    _Tags  _AnswerCount  _CommentCount  _FavoriteCount  \\\n",
       "0  <discussion><on-topic>           3.0              0             NaN   \n",
       "1   <discussion><tagging>           1.0              1             NaN   \n",
       "\n",
       "   _LastEditorUserId  _AcceptedAnswerId            _LastEditDate  _ParentId  \\\n",
       "0                8.0                NaN  2011-10-26T05:35:32.733        NaN   \n",
       "1                8.0               16.0  2011-10-26T05:32:58.667        NaN   \n",
       "\n",
       "   Unnamed: 17  Unnamed: 18 Unnamed: 19  \n",
       "0          NaN          NaN         NaN  \n",
       "1          NaN          NaN         NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=test.fillna(\"\")\n",
    "test=test[['_Body']]\n",
    "test = cleanBody(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               _Body|            new_body|\n",
      "+--------------------+--------------------+\n",
      "|<p>Are questions ...|Are questions rel...|\n",
      "|<p>What is a good...|What is a good ta...|\n",
      "|<p>I've asked one...|I've asked one, s...|\n",
      "|<p>Lego Mindstorm...|Lego Mindstorms a...|\n",
      "|<p>I suspect that...|I suspect that Mi...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the saved model created before and predict for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               _Body|            new_body|               words|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|<p>Are questions ...|Are questions rel...|[are, questions, ...|[questions, relat...|(500,[22,114,182,...|(500,[22,114,182,...|[4.80119047619047...|[0.04801190476190...|       2.0|\n",
      "|<p>What is a good...|What is a good ta...|[what, is, a, goo...|[good, tag, purch...|(500,[39,76,85,88...|(500,[39,76,85,88...|[5.40277777777777...|[0.05402777777777...|       2.0|\n",
      "|<p>I've asked one...|I've asked one, s...|[i've, asked, one...|[asked, one,, fin...|(500,[7,10,11,44,...|(500,[7,10,11,44,...|[11.3611111111111...|[0.11361111111111...|       2.0|\n",
      "|<p>Lego Mindstorm...|Lego Mindstorms a...|[lego, mindstorms...|[lego, mindstorms...|(500,[24,36,44,11...|(500,[24,36,44,11...|[2.30952380952380...|[0.02309523809523...|       2.0|\n",
      "|<p>I suspect that...|I suspect that Mi...|[i, suspect, that...|[suspect, mindsto...|(500,[161,214,234...|(500,[161,214,234...|[1.95833333333333...|[0.01958333333333...|       2.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions_test = cvModelRF.transform(testDf)\n",
    "predictions_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Body</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Are questions related to &lt;a href=\"http://ww...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;What is a good tag for purchasing/acquiring...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;I've asked one, so &lt;a href=\"https://bricks....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Lego Mindstorms allows one to write embedde...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;I suspect that Mindstorms by itself is not ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               _Body  prediction\n",
       "0  <p>Are questions related to <a href=\"http://ww...         2.0\n",
       "1  <p>What is a good tag for purchasing/acquiring...         2.0\n",
       "2  <p>I've asked one, so <a href=\"https://bricks....         2.0\n",
       "3  <p>Lego Mindstorms allows one to write embedde...         2.0\n",
       "4  <p>I suspect that Mindstorms by itself is not ...         2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_test = predictions_test.select('_Body')\n",
    "pred_test = predictions_test.select('prediction')\n",
    "df5 =pd.concat([body_test.toPandas() ,pred_test.toPandas()], axis=1)\n",
    "df5.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchval(key):\n",
    "    return dct[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['predicted_label'] = df5.apply(lambda row: fetchval(row['prediction']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Body</th>\n",
       "      <th>prediction</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>&lt;p&gt;I think that hardware recommendations are o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3dprinting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Yes - in some cases.&lt;/strong&gt;&lt;/p&gt;\\n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3dprinting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Yes!&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Absolutely....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>bricks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>&lt;p&gt;I believe this question is asked on every p...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>avp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>&lt;p&gt;When asking my first question, I noticed we...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3dprinting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;The Hotbed.&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Coll...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3dprinting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>&lt;p&gt;\"print-quality\" is a better (more specific)...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>agur.meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>&lt;p&gt;I would say that &lt;strong&gt;they are on topic&lt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3dprinting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>&lt;p&gt;I would like to nominate myself, &lt;a href=\"h...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3dprinting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>&lt;h1&gt;Filibusters!&lt;/h1&gt;\\n\\n&lt;p&gt;I've heard that fr...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>avp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _Body  prediction  \\\n",
       "491  <p>I think that hardware recommendations are o...         0.0   \n",
       "492  <p><strong>Yes - in some cases.</strong></p>\\n...         0.0   \n",
       "493  <p><strong>Yes!</strong></p>\\n\\n<p>Absolutely....         2.0   \n",
       "494  <p>I believe this question is asked on every p...         7.0   \n",
       "495  <p>When asking my first question, I noticed we...         0.0   \n",
       "496  <p><strong>The Hotbed.</strong></p>\\n\\n<p>Coll...         0.0   \n",
       "497  <p>\"print-quality\" is a better (more specific)...         4.0   \n",
       "498  <p>I would say that <strong>they are on topic<...         0.0   \n",
       "499  <p>I would like to nominate myself, <a href=\"h...         0.0   \n",
       "500  <h1>Filibusters!</h1>\\n\\n<p>I've heard that fr...         7.0   \n",
       "\n",
       "    predicted_label  \n",
       "491      3dprinting  \n",
       "492      3dprinting  \n",
       "493          bricks  \n",
       "494             avp  \n",
       "495      3dprinting  \n",
       "496      3dprinting  \n",
       "497       agur.meta  \n",
       "498      3dprinting  \n",
       "499      3dprinting  \n",
       "500             avp  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions have been saved to test_predictions.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(\"test_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
